{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/map-volume/255_19/test_results/sequences')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# lidarlist_path = Path(\"/root/map-volume/output/sequences\")\n",
    "lidarlist_path = Path(\"/root/map-volume/255_19/test_results/sequences\")\n",
    "# lidarlist_path = Path(\"/root/datasets/kitti_lidarseg/sequences\") 20351\n",
    "\n",
    "lidarlist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16', '13', '11', '12', '19', '17', '18', '20', '21', '14', '15']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = os.listdir(lidarlist_path)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       " ['11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/root/iSphereFormer/util/semantic-kitti-19.yaml\", 'r') as stream:\n",
    "    semkittiyaml = yaml.safe_load(stream)\n",
    "splits = semkittiyaml['split']['test']\n",
    "splits, [str(i) for i in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20351"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = os.listdir(lidarlist_path)\n",
    "num_files = 0\n",
    "for f in file_list:\n",
    "    # if f not in [str(i) for i in splits]:\n",
    "    #     continue\n",
    "    # file_path = lidarlist_path / f / \"velodyne\"\n",
    "    file_path = lidarlist_path / f / \"predictions\"\n",
    "    label_list = os.listdir(file_path)\n",
    "    num_files += len(label_list)\n",
    "\n",
    "num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 10,\n",
       " 2: 11,\n",
       " 3: 15,\n",
       " 4: 18,\n",
       " 5: 20,\n",
       " 6: 30,\n",
       " 7: 31,\n",
       " 8: 32,\n",
       " 9: 40,\n",
       " 10: 44,\n",
       " 11: 48,\n",
       " 12: 49,\n",
       " 13: 50,\n",
       " 14: 51,\n",
       " 15: 70,\n",
       " 16: 71,\n",
       " 17: 72,\n",
       " 18: 80,\n",
       " 19: 81,\n",
       " 20: 252,\n",
       " 21: 253,\n",
       " 22: 254,\n",
       " 23: 255,\n",
       " 24: 259,\n",
       " 25: 258}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/root/iSphereFormer/util/semantic-kitti-all.yaml\", 'r') as stream:\n",
    "    semkittiyaml = yaml.safe_load(stream)\n",
    "learning_map_inv = semkittiyaml['learning_map_inv']\n",
    "learning_map_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root_path = Path(\"/root/map-volume/output/sequences\")\n",
    "if not save_root_path.exists():\n",
    "    save_root_path.mkdir(parents=True, exist_ok=True)\n",
    "convert_F = lambda label: (0xFFFF << 16) | label\n",
    "for f in file_list:\n",
    "    file_path = lidarlist_path / f / \"predictions\"\n",
    "    label_list = os.listdir(file_path)\n",
    "    for label_name in label_list:\n",
    "        label_path = file_path / label_name\n",
    "        save_path = save_root_path / label_path.relative_to(lidarlist_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        label = np.fromfile(label_path, dtype=np.uint32)\n",
    "        # print(label)\n",
    "        annotated_data = np.vectorize(learning_map_inv.__getitem__, otypes=[np.uint32])(label)\n",
    "        # print(convert_F(label))\n",
    "        # annotated_data = convert_F(label)\n",
    "        # print(save_path, save_path.parent)\n",
    "        # print(np.unique(annotated_data))\n",
    "        annotated_data.tofile(str(save_path))\n",
    "        # convert_data = np.fromfile(save_path, dtype=np.uint32)\n",
    "        # print(convert_data.shape)\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((126855,),\n",
       " array([10, 15, 40, 44, 48, 50, 51, 70, 71, 72, 80, 81], dtype=uint32))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = lidarlist_path / \"16/predictions/000011.label\"\n",
    "f = np.fromfile(fpath, dtype=np.uint32)\n",
    "# convert_f = lambda label: (0xFFFF << 16) | label\n",
    "# bf = convert_f(f)\n",
    "cf = f & 0xFFFF\n",
    "f.shape, np.unique(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ascii_pcd(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    points = []\n",
    "    header = True\n",
    "    for line in lines:\n",
    "        if header:\n",
    "            if line.startswith(\"DATA\"):\n",
    "                header = False\n",
    "        else:\n",
    "            points.append([float(value) for value in line.strip().split()])\n",
    "\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4071"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidarlist_path = Path(\"/root/datasets/kitti_lidarseg\")\n",
    "file_list = os.listdir(lidarlist_path)\n",
    "with open(\"/root/iSphereFormer/util/semantic-kitti-19.yaml\", 'r') as stream:\n",
    "# with open(\"/root/iSphereFormer/util/semantic-kitti-all.yaml\", 'r') as stream:\n",
    "    semkittiyaml = yaml.safe_load(stream)\n",
    "splits = semkittiyaml['split']['valid']\n",
    "learning_map = semkittiyaml['learning_map']\n",
    "files = []\n",
    "import glob\n",
    "for i_folder in splits:\n",
    "    files += sorted(glob.glob(os.path.join(lidarlist_path, \"sequences\", str(i_folder).zfill(2), 'labels', \"*.label\")))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter()\n",
    "\n",
    "for file_path in files:\n",
    "    raw_data = np.fromfile(file_path, dtype=np.uint32)\n",
    "    annotated_data = raw_data & 0xFFFF  # delete high 16 digits binary\n",
    "    annotated_data = np.vectorize(learning_map.__getitem__)(annotated_data)\n",
    "    # print(np.unique(annotated_data, return_counts=True))\n",
    "    # print(annotated_data.shape)\n",
    "    counts.update(annotated_data)\n",
    "    # break\n",
    "\n",
    "# for label, count in counts.items():\n",
    "    # print(f\"label {label}: {count}\")\n",
    "labels = [label for label, _ in counts.items()]\n",
    "np.sort(np.array(labels).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 22321839),\n",
       " (1, 30856105),\n",
       " (2, 247796),\n",
       " (3, 345868),\n",
       " (4, 508704),\n",
       " (5, 2222268),\n",
       " (6, 476946),\n",
       " (7, 306860),\n",
       " (8, 22737),\n",
       " (9, 87963626),\n",
       " (10, 5947692),\n",
       " (11, 60280496),\n",
       " (12, 457650),\n",
       " (13, 56878900),\n",
       " (14, 12642657),\n",
       " (15, 145937016),\n",
       " (16, 5503279),\n",
       " (17, 64111254),\n",
       " (18, 1666427),\n",
       " (19, 381442)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items = sorted(counts.items())\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.4799176268586114e-08,\n",
       " 1: 3.2408497443212614e-08,\n",
       " 2: 4.035577652585191e-06,\n",
       " 3: 2.8912764407230504e-06,\n",
       " 4: 1.9657797068629302e-06,\n",
       " 5: 4.4999073019095804e-07,\n",
       " 6: 2.0966734179550726e-06,\n",
       " 7: 3.258815094831519e-06,\n",
       " 8: 4.3981176056647754e-05,\n",
       " 9: 1.1368335361709623e-08,\n",
       " 10: 1.681324453250101e-07,\n",
       " 11: 1.658911366621801e-08,\n",
       " 12: 2.185075931388616e-06,\n",
       " 13: 1.7581212013593792e-08,\n",
       " 14: 7.90972973481761e-08,\n",
       " 15: 6.852271119480749e-09,\n",
       " 16: 1.817098497096004e-07,\n",
       " 17: 1.5597885513204906e-08,\n",
       " 18: 6.000862924088484e-07,\n",
       " 19: 2.6216305493364654e-06}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: 1 / value if value != 0 else float('inf') for key, value in sorted_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19,),\n",
       " array([ 30856105,    247796,    345868,    508704,   2222268,    476946,\n",
       "           306860,     22737,  87963626,   5947692,  60280496,    457650,\n",
       "         56878900,  12642657, 145937016,   5503279,  64111254,   1666427,\n",
       "           381442], dtype=uint32),\n",
       " array([5.01559814e-04, 6.24553354e-02, 4.47459213e-02, 3.04227651e-02,\n",
       "        6.96413857e-03, 3.24485000e-02, 5.04340165e-02, 6.80660698e-01,\n",
       "        1.75938430e-04, 2.60204837e-03, 2.56736147e-04, 3.38166334e-02,\n",
       "        2.72090042e-04, 1.22412419e-03, 1.06046997e-04, 2.81217476e-03,\n",
       "        2.41395720e-04, 9.28704485e-03, 4.05728323e-02]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([value for key, value in sorted_items if key not in [0]], dtype=np.uint32).reshape(-1)\n",
    "weights = 1.0 / a\n",
    "weights = weights / weights.sum()\n",
    "a.shape, a, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.20192540e-02, 8.95091359e+00, 6.41634658e+00, 4.36439902e+00,\n",
       "        9.99785509e-01, 4.65471736e+00, 7.23072637e+00, 9.57306450e+01,\n",
       "        2.52633510e-02, 3.73605405e-01, 3.68651649e-02, 4.85077102e+00,\n",
       "        3.90698374e-02, 1.75768764e-01, 1.52275331e-02, 4.03773005e-01,\n",
       "        3.46624241e-02, 1.33317115e+00, 5.81869299e+00]),\n",
       " array([7.2000e-02, 8.9510e+00, 6.4160e+00, 4.3640e+00, 1.0000e+00,\n",
       "        4.6550e+00, 7.2310e+00, 9.5731e+01, 2.5000e-02, 3.7400e-01,\n",
       "        3.7000e-02, 4.8510e+00, 3.9000e-02, 1.7600e-01, 1.5000e-02,\n",
       "        4.0400e-01, 3.5000e-02, 1.3330e+00, 5.8190e+00]),\n",
       " (19,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = a / a.sum()\n",
    "median_freq = np.median(freqs[freqs > 0])\n",
    "weights = median_freq / (freqs + 1e-6)\n",
    "weights, np.round(weights, 3), weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 73587231\n",
      "label 16: 14189414\n",
      "label 19: 1441988\n",
      "label 13: 311802516\n",
      "label 18: 6712285\n",
      "label 15: 627195745\n",
      "label 1: 95302518\n",
      "label 23: 87766\n",
      "label 11: 338183720\n",
      "label 10: 34577789\n",
      "label 9: 467085589\n",
      "label 17: 183603141\n",
      "label 14: 170001681\n",
      "label 22: 376574\n",
      "label 5: 5086370\n",
      "label 20: 4128968\n",
      "label 8: 13\n",
      "label 21: 298599\n",
      "label 2: 391766\n",
      "label 12: 9173976\n",
      "label 3: 936031\n",
      "label 6: 440239\n",
      "label 7: 5\n",
      "label 4: 4347360\n",
      "label 24: 369518\n",
      "label 25: 238730\n"
     ]
    }
   ],
   "source": [
    "for label, count in counts.items():\n",
    "    print(f\"label {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 44601775\n",
      "label 1: 2299457602\n",
      "label 2: 5500155\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter()\n",
    "\n",
    "for file_path in files:\n",
    "    raw_data = np.fromfile(file_path, dtype=np.uint32)\n",
    "    annotated_data = raw_data & 0xFFFF  # delete high 16 digits binary\n",
    "    annotated_data = np.vectorize(learning_map.__getitem__)(annotated_data)\n",
    "    # print(np.unique(annotated_data, return_counts=True))\n",
    "    # print(annotated_data.shape)\n",
    "    counts.update(annotated_data)\n",
    "    # break\n",
    "\n",
    "for label, count in counts.items():\n",
    "    print(f\"label {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33875888, 0.27679872, 0.3844424 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class_counts = np.zeros(3, dtype=np.uint32)\n",
    "for label, count in counts.items():\n",
    "    class_counts[label] = count\n",
    "class_weights = 1.0 / np.log(class_counts + 1)\n",
    "class_weights = class_weights / np.sum(class_weights)  # 归一化\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_triplet(a: float, delta: float = 0.1):\n",
    "    offsets = [random.uniform(-delta, delta) for _ in range(2)]  # 生成两个随机偏移量\n",
    "    x1 = a + offsets[0]\n",
    "    x2 = a + offsets[1]\n",
    "    x3 = 3 * a - (x1 + x2)  # 确保均值为 a\n",
    "    return x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83.68811353318029, 83.70599325288988, 82.80589321392986)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_triplet(83.4, delta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.miniconda/envs/mamba-is/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 time: 1.2053s\n",
      "AMP (FP16) time: 0.1172s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = \"cuda\"\n",
    "x = torch.randn(1024, 1024, device=device)\n",
    "y = torch.randn(1024, 1024, device=device)\n",
    "\n",
    "# FP32 测试\n",
    "start = time.time()\n",
    "for _ in range(1000):\n",
    "    _ = torch.matmul(x, y)\n",
    "print(f\"FP32 time: {time.time() - start:.4f}s\")\n",
    "\n",
    "# FP16 测试（AMP）\n",
    "with torch.cuda.amp.autocast():\n",
    "    start = time.time()\n",
    "    for _ in range(1000):\n",
    "        _ = torch.matmul(x, y)\n",
    "    print(f\"AMP (FP16) time: {time.time() - start:.4f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba-is",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
